{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "PATH = \"Datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#food_emissions = pd.read_csv(PATH+\"Food_Product_Emissions.csv\")\n",
    "#food_emissions.drop(['Unit of GHG Emissions'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_prod = pd.read_csv(PATH+\"meat_prod.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Entity', 'Code', 'Year', 'Cattle | Produced', 'Goat | Produced',\n",
       "       'Chicken | Produced', 'Turkey | Produced', 'Pig | Produced',\n",
       "       'Lamb and mutton | Produced', 'Meat, Total | tonnes', 'Game | tonnes',\n",
       "       'Duck | tonnes', 'Horse | tonnes', 'Camel | tonnes',\n",
       "       'Goose and guinea fowl | tonnes', 'Sheep and goat | tonnes',\n",
       "       'Beef and buffalo | tonnes', 'Pig | tonnes', 'Poultry | tonnes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meat_prod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_prod.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.unique(meat_prod.Year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLastYear(df,entities,nb_year=0):\n",
    "   new_df = pd.DataFrame()\n",
    "   for e in entities:\n",
    "      #remove bad country\n",
    "      if len(e.split(\"(\")) < 2:\n",
    "         _lastYear = df[df['Entity'] == e].iloc[-1]\n",
    "         if _lastYear['Year'] == max(np.unique(meat_prod.Year)):\n",
    "            if nb_year:\n",
    "               _lastYear = df[df['Entity'] == e].iloc[-nb_year:]\n",
    "               if(min(_lastYear.Year) == min(meat_prod[meat_prod['Entity'] == \"France\"].iloc[-10:].Year) and len(_lastYear) == nb_year):\n",
    "                  new_df = new_df.append(_lastYear)\n",
    "            else:\n",
    "               new_df = new_df.append(_lastYear)\n",
    "   return new_df\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_prod_last_year = getLastYear(meat_prod,np.unique(meat_prod['Entity']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertProd(df):\n",
    "    #irrelevent meta data info\n",
    "    df.drop(['Code'],axis=1,inplace=True)\n",
    "\n",
    "    #dropping every columns that refer to the tonnes\n",
    "    df.drop(['Meat, Total | tonnes', 'Game | tonnes',\n",
    "        'Duck | tonnes', 'Horse | tonnes', 'Camel | tonnes',\n",
    "        'Goose and guinea fowl | tonnes', 'Sheep and goat | tonnes',\n",
    "        'Beef and buffalo | tonnes', 'Pig | tonnes', 'Poultry | tonnes'],axis=1,inplace=True)\n",
    "\n",
    "    #dropping turkey because almost useless\n",
    "    df.drop(['Turkey | Produced'],axis=1,inplace=True)\n",
    "    #adding total animals produced\n",
    "    df['Meat, Total | Produced'] = df.sum(axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Combal\\AppData\\Local\\Temp/ipykernel_11552/1563307950.py:14: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df['Meat, Total | Produced'] = df.sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "meat_prod_last_year = convertProd(getLastYear(meat_prod,np.unique(meat_prod['Entity'])).copy()).drop(['Year'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Combal\\AppData\\Local\\Temp/ipykernel_11552/1563307950.py:14: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df['Meat, Total | Produced'] = df.sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "meat_prod_10_last_years = convertProd(getLastYear(meat_prod,np.unique(meat_prod['Entity']),10).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_prod_last_year.to_csv(\"meat_prod_last_year.csv\",sep=\";\")\n",
    "meat_prod_10_last_years.to_csv(\"meat_prod_10_years.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_prod_last_year.set_index('Entity').to_json(\"meat_prod_last_year.json\",orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = np.unique(meat_prod_10_last_years.Entity)\n",
    "res = {}\n",
    "for e in entities:\n",
    "    res[e] = {}\n",
    "    for _, row in meat_prod_10_last_years[meat_prod_10_last_years['Entity'] == e].iterrows():\n",
    "        res[e][row.Year] = {\n",
    "                                \"Meat, Total | Produced\":       row[\"Meat, Total | Produced\"],\n",
    "                                \"Cattle | Produced\":            row[\"Cattle | Produced\"],\n",
    "                                \"Goat | Produced\":              row[\"Goat | Produced\"],\n",
    "                                \"Chicken | Produced\":           row[\"Chicken | Produced\" ],\n",
    "                                \"Pig | Produced\":               row[\"Pig | Produced\"],\n",
    "                                \"Lamb and mutton | Produced\":   row[\"Lamb and mutton | Produced\"]\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"meat_prod_10_last_years.json\", \"w\") as fp:\n",
    "    json.dump(res,fp) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tonnes Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTonnes(df):\n",
    "   #irrelevent meta data info\n",
    "   df.drop(['Code'],axis=1,inplace=True)\n",
    "\n",
    "   #dropping every columns that refer to the Production\n",
    "   df.drop(['Cattle | Produced', 'Goat | Produced',\n",
    "      'Chicken | Produced', 'Turkey | Produced', 'Pig | Produced',\n",
    "      'Lamb and mutton | Produced',],axis=1,inplace=True)\n",
    "\n",
    "   #dropping because almost useless or too specific\n",
    "   df.drop(['Game | tonnes',\n",
    "      'Horse | tonnes', 'Camel | tonnes',],axis=1,inplace=True)\n",
    "   \n",
    "   #computing chicken from poultry \n",
    "   df['Chicken | tonnes'] = df['Poultry | tonnes'] - (df['Duck | tonnes'] + df['Goose and guinea fowl | tonnes'])\n",
    "   df.drop(['Poultry | tonnes'],axis=1,inplace=True)\n",
    "\n",
    "   #recomputing total animals in tonnes because we removed some\n",
    "   \n",
    "   df['Meat, Total | tonnes'] = df.drop(['Meat, Total | tonnes'],axis=1).sum(axis=1)\n",
    "   \n",
    "   return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Combal\\AppData\\Local\\Temp/ipykernel_11552/4052391698.py:20: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df['Meat, Total | tonnes'] = df.drop(['Meat, Total | tonnes'],axis=1).sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "meat_tonnes_last_year = convertTonnes(getLastYear(meat_prod,np.unique(meat_prod['Entity'])).copy()).drop(['Year'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Combal\\AppData\\Local\\Temp/ipykernel_11552/4052391698.py:20: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df['Meat, Total | tonnes'] = df.drop(['Meat, Total | tonnes'],axis=1).sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "meat_tonnes_10_last_years = convertTonnes(getLastYear(meat_prod,np.unique(meat_prod['Entity']),10).copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_tonnes_last_year.to_csv(\"meat_tonnes_last_year.csv\",sep=\";\")\n",
    "meat_tonnes_10_last_years.to_csv(\"meat_tonnes_10_years.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_tonnes_last_year.set_index('Entity').to_json(\"meat_tonnes_last_year.json\",orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = np.unique(meat_tonnes_10_last_years.Entity)\n",
    "res = {}\n",
    "for e in entities:\n",
    "    res[e] = {}\n",
    "    for _, row in meat_tonnes_10_last_years[meat_tonnes_10_last_years['Entity'] == e].iterrows():\n",
    "        res[e][row.Year] = {\n",
    "                                \"Meat, Total | tonnes\":             row[\"Meat, Total | tonnes\"],\n",
    "                                \"Duck | tonnes\":                    row[\"Duck | tonnes\"],\n",
    "                                \"Goose and guinea fowl | tonnes\":   row[\"Goose and guinea fowl | tonnes\"],\n",
    "                                \"Sheep and goat | tonnes\":          row[\"Sheep and goat | tonnes\"],\n",
    "                                \"Beef and buffalo | tonnes\":        row[\"Beef and buffalo | tonnes\"],\n",
    "                                \"Pig | tonnes\":                     row[\"Pig | tonnes\"],\n",
    "                                \"Chicken | tonnes \":                row[\"Chicken | tonnes\"]\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"meat_tonnes_10_last_years.json\", \"w\") as fp:\n",
    "    json.dump(res,fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67971f46f0fa2eec564b13cddb8a1a061a836eb7a6955f65d67366ebef87f4ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
